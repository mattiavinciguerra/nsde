{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d09e23",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d444399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 200 5 161\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/Users/mattia/Documents/Scuola/UNI/Magistrale/Tesi/Preprocessing/fixs.pkl\", \"rb\") as f:\n",
    "    fixs = pickle.load(f)\n",
    "\n",
    "print(len(fixs), len(fixs[0]), len(fixs[0][0]), len(fixs[0][0][0]))\n",
    "# n_sbj x n_img x n_fix x n_coord x 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5e60d",
   "metadata": {},
   "source": [
    "# LatentSDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae5b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchsde\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeec5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Sequence\n",
    "\n",
    "import fire\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3211847",
   "metadata": {},
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f24568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1, iters)\n",
    "        self._val = maxval / self._iters\n",
    "        self._maxval = maxval\n",
    "\n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val + self._maxval / self._iters)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35fe75e",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Prende in input la sequenza osservata xs e ne produce un contesto ctx, che verrà usato per condizionare i termini drift/diffusione della SDE.\n",
    "- GRU: aggrega l’informazione nel tempo.\n",
    "- Linear: riduce la dimensionalità a context_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3c5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inp, lengths):\n",
    "        # inp: [T, B, input_size]\n",
    "        # lengths: [B] → lunghezze reali (senza padding)\n",
    "\n",
    "        # Ordina per lunghezza decrescente (richiesto da pack_padded_sequence)\n",
    "        lengths_sorted, perm_idx = lengths.sort(0, descending=True)\n",
    "        inp_sorted = inp[:, perm_idx]\n",
    "\n",
    "        # Impacchetta la sequenza\n",
    "        packed = pack_padded_sequence(inp_sorted, lengths_sorted.cpu(), enforce_sorted=True)\n",
    "\n",
    "        # Passa alla GRU\n",
    "        packed_out, _ = self.gru(packed)\n",
    "\n",
    "        # Deimpacchetta\n",
    "        out, _ = pad_packed_sequence(packed_out)\n",
    "\n",
    "        # Ripristina l'ordine originale del batch\n",
    "        _, unperm_idx = perm_idx.sort(0)\n",
    "        out = out[:, unperm_idx]\n",
    "\n",
    "        # Passa alla linear\n",
    "        out = self.lin(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069324d",
   "metadata": {},
   "source": [
    "## LatentSDE\n",
    "Implementa un modello generativo basato su SDE in uno spazio latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb5f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "class LatentSDE(nn.Module):\n",
    "    sde_type = \"ito\"\n",
    "    noise_type = \"diagonal\"\n",
    "\n",
    "    def __init__(self, data_size, latent_size, context_size, hidden_size):\n",
    "        super(LatentSDE, self).__init__()\n",
    "\n",
    "        # Encoder: calcola un contesto temporale ctx(t) dalla sequenza osservata xs\n",
    "        self.encoder = Encoder(input_size=data_size, hidden_size=hidden_size, output_size=context_size)\n",
    "\n",
    "        # Posterior su z0: approssima la distribuzione posteriore su z0 (il punto iniziale nello spazio latente)\n",
    "        # Produce la media e log-varianza\n",
    "        self.qz0_net = nn.Linear(context_size, latent_size + latent_size)\n",
    "\n",
    "        # Decoder\n",
    "        # Drift condizionato sul contesto -> usato nel forward path\n",
    "        self.f_net = nn.Sequential(\n",
    "            nn.Linear(latent_size + context_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        # Drift del modello generativo -> usato per generazione/sampling\n",
    "        self.h_net = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "\n",
    "        # This needs to be an element-wise function for the SDE to satisfy diagonal noise\n",
    "        # Diffusione diagonale -> ogni dimensione ha la sua rete (richiesto per noise diagonale)\n",
    "        self.g_nets = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(1, hidden_size),\n",
    "                    nn.Softplus(),\n",
    "                    nn.Linear(hidden_size, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "                for _ in range(latent_size)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Proietta il processo latente nello spazio osservabile per confrontarlo con i dati osservati\n",
    "        self.projector = nn.Linear(latent_size, data_size)\n",
    "\n",
    "        # Prior su z0: distribuzione prior su z0 (punto iniziale nello spazio latente)\n",
    "        # Inizializza la distribuzione prior su z0 come una normale standard (media zero e varianza uno)\n",
    "        # Parametri di un prior normale standard su z0 (trainabili)\n",
    "        self.pz0_mean = nn.Parameter(torch.zeros(1, latent_size))\n",
    "        self.pz0_logstd = nn.Parameter(torch.zeros(1, latent_size))\n",
    "\n",
    "        self._ctx = None\n",
    "\n",
    "    # Memorizza il contesto temporale calcolato dall'encoder (una coppia (ts, ctx) per l'accesso temporale nel drift),\n",
    "    # usato per calcolare la drift condizionata sul contesto\n",
    "    # e per il calcolo della distribuzione posteriore su z0.\n",
    "    # Il contesto è una sequenza di vettori di dimensione [T, batch_size, context_size], T lunghezza della sequenza.\n",
    "    # Viene calcolato dall'encoder e passato come input al modello SDE.\n",
    "    def contextualize(self, ctx):\n",
    "        self._ctx = ctx\n",
    "\n",
    "    # Cerca il contesto ctx(t) interpolando (step-wise) e concatena a y per usare f_net.\n",
    "    def f(self, t, y):\n",
    "        ts, ctx = self._ctx\n",
    "        i = min(torch.searchsorted(ts, t, right=True), len(ts) - 1)\n",
    "        return self.f_net(torch.cat((y, ctx[i]), dim=1))\n",
    "\n",
    "    def h(self, t, y):\n",
    "        return self.h_net(y)\n",
    "\n",
    "    # Diffusione diagonale\n",
    "    def g(self, t, y):\n",
    "        y = torch.split(y, split_size_or_sections=1, dim=1)\n",
    "        out = [g_net_i(y_i) for (g_net_i, y_i) in zip(self.g_nets, y)]\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    # Training\n",
    "    def forward(self, xs, mask, ts, noise_std, adjoint=False, method=\"euler\"):\n",
    "        # Context encoding (contextualization is only needed for posterior inference)\n",
    "        ctx = self.encoder(torch.flip(xs, dims=(0,)), torch.flip(mask, dims=(0,)).sum(dim=0).long()) # params: xs, lengths (sequences lengths without padding)\n",
    "        ctx = torch.flip(ctx, dims=(0,))\n",
    "        self.contextualize((ts, ctx))\n",
    "\n",
    "        # Compute the posterior distribution q(z0|x0), conditioned on the context ctx(t), and sample z0\n",
    "        # q(z0|x0) = N(qz0_mean, qz0_logstd.exp())\n",
    "        # where qz0_mean and qz0_logstd are computed by the qz0_net.\n",
    "        # The posterior is used to\n",
    "        #   - sample the initial point z0 in the latent space.\n",
    "        #   - compute the KL divergence term in the loss function.\n",
    "        #   - compute the log probability of the path in the latent space.\n",
    "        #   - compute the log probability of the initial point z0 in the latent space.\n",
    "        qz0_mean, qz0_logstd = self.qz0_net(ctx[0]).chunk(chunks=2, dim=1)\n",
    "        z0 = qz0_mean + qz0_logstd.exp() * torch.randn_like(qz0_mean)\n",
    "\n",
    "        # Simulate the SDE path in the latent space\n",
    "        if adjoint:\n",
    "            # Must use the argument `adjoint_params`, since `ctx` is not part of the input to `f`, `g`, and `h`.\n",
    "            adjoint_params = (\n",
    "                    (ctx,) +\n",
    "                    tuple(self.f_net.parameters()) + tuple(self.g_nets.parameters()) + tuple(self.h_net.parameters())\n",
    "            )\n",
    "            # Integrate the SDE using the adjoint method\n",
    "            zs, log_ratio = torchsde.sdeint_adjoint(\n",
    "                self, z0, ts, adjoint_params=adjoint_params, dt=1e-2, logqp=True, method=method)\n",
    "        else:\n",
    "            zs, log_ratio = torchsde.sdeint(self, z0, ts, dt=1e-2, logqp=True, method=method)\n",
    "        # zs is a tensor of shape [T, batch_size, latent_dim], where T is the number of time steps.\n",
    "        # log_ratio is a tensor of shape [T, batch_size], containing the log probability ratio of the path. \n",
    "\n",
    "        # Project the latent path zs into the observation space xs\n",
    "        _xs = self.projector(zs)\n",
    "\n",
    "        # Distribuzione normale con media _xs e deviazione standard noise_std.\n",
    "        xs_dist = Normal(loc=_xs, scale=noise_std)\n",
    "\n",
    "        # Confronta le osservazioni xs con le osservazioni ricostruite _xs\n",
    "        # xs_dist.log_prob(xs) calcola il logaritmo della probabilità delle osservazioni xs date le osservazioni ricostruite _xs.\n",
    "        log_prob = xs_dist.log_prob(xs)  # [T, B, D]\n",
    "        mask = mask.unsqueeze(-1) # mask: [T, B] → [T, B, 1]\n",
    "        log_prob = log_prob * mask  # [T, B, D]\n",
    "        # La somma lungo le dimensioni (0, 2) calcola il logaritmo della probabilità per ogni osservazione xs.\n",
    "        # La media lungo la dimensione 0 calcola la probabilità media per batch.\n",
    "        log_pxs = log_prob.sum(dim=(0, 2)).mean(dim=0)\n",
    "\n",
    "        # Calcola la divergenza KL tra la distribuzione posteriore q(z0|x0) e la distribuzione prior p(z0)\n",
    "        qz0 = Normal(loc=qz0_mean, scale=qz0_logstd.exp())\n",
    "        pz0 = Normal(loc=self.pz0_mean, scale=self.pz0_logstd.exp())\n",
    "        \n",
    "        # logqp0 is the log probability of the initial point z0 in the latent space, which is computed by the posterior.\n",
    "        logqp0 = torch.distributions.kl_divergence(qz0, pz0).sum(dim=1).mean(dim=0)\n",
    "\n",
    "        # logqp_path is the log probability of the path in the latent space, which is computed by the SDE solver.\n",
    "        logqp_path = log_ratio.sum(dim=0).mean(dim=0)\n",
    "\n",
    "        return log_pxs, logqp0 + logqp_path\n",
    "\n",
    "    # Generazione\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size, ts, bm=None):\n",
    "        eps = torch.randn(size=(batch_size, *self.pz0_mean.shape[1:]), device=self.pz0_mean.device)\n",
    "        # Sample z0 from the prior p(z0)\n",
    "        z0 = self.pz0_mean + self.pz0_logstd.exp() * eps\n",
    "\n",
    "        # Context is not needed for sampling, so we can ignore it.\n",
    "        # Simulate the SDE path in the latent space\n",
    "        zs = torchsde.sdeint(self, z0, ts, names={'drift': 'h'}, dt=1e-3, bm=bm)\n",
    "        # Most of the times in ML, we don't sample the observation noise for visualization purposes.\n",
    "        # Project the latent path zs into the observation space xs\n",
    "        _xs = self.projector(zs)\n",
    "        return _xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c5509",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6970f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    lengths = torch.tensor([seq.shape[0] for seq in batch])\n",
    "    # Padding the sequences to the maximum length in the batch\n",
    "    padded = pad_sequence(batch, batch_first=False) # [T, B, 2]\n",
    "    mask = torch.arange(padded.shape[0]).unsqueeze(1) < lengths.unsqueeze(0)\n",
    "    mask = mask.float()  # Convert to float for compatibility with loss functions\n",
    "    return padded, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "361607e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_dataloaders(sbj_fixs, batch_size):\n",
    "    # Mescola le traiettorie\n",
    "    random.shuffle(sbj_fixs)\n",
    "    \n",
    "    # Suddivisione 70% training, 15% validation, 15% test\n",
    "    train_size = int(0.7 * len(sbj_fixs))\n",
    "    val_size = int(0.15 * len(sbj_fixs))\n",
    "    train_set = [torch.tensor(fix, dtype=torch.float) for img in sbj_fixs[:train_size] for fix in img]\n",
    "    val_set = [torch.tensor(fix, dtype=torch.float) for img in sbj_fixs[train_size:train_size + val_size] for fix in img]\n",
    "    test_set = [torch.tensor(fix, dtype=torch.float) for img in sbj_fixs[train_size + val_size:] for fix in img]\n",
    "\n",
    "    # Crea i DataLoader\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e0a8e",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c7eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "data_size=2\n",
    "latent_size=8\n",
    "context_size=64\n",
    "hidden_size=128\n",
    "lr_init=1e-3\n",
    "lr_gamma=1.0 # 0.997\n",
    "num_iters=200\n",
    "kl_anneal_iters=1000\n",
    "log_every=10\n",
    "noise_std=0.01\n",
    "adjoint=False\n",
    "method=\"euler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e9f28",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08835e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on subject 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [14:44<4:49:04, 91.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbj 4 | [010] loss: 9025539.0 | val_loss: 7594075.5 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [30:22<4:37:04, 92.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbj 4 | [020] loss: 8658181.0 | val_loss: 7315069.5 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [44:46<4:01:15, 85.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbj 4 | [030] loss: 6893407.5 | val_loss: 6364358.5 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [58:41<3:43:09, 83.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbj 4 | [040] loss: 7076530.5 | val_loss: 6268437.5 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [1:12:44<3:35:11, 86.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbj 4 | [050] loss: 6736947.0 | val_loss: 6241736.5 | \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi è verificato un arresto anomalo del Kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. \n",
      "\u001b[1;31mEsaminare il codice nelle celle per identificare una possibile causa dell'errore. \n",
      "\u001b[1;31mPer altre informazioni, fare clic<a href='https://aka.ms/vscodeJupyterKernelCrash'>qui</a>. \n",
      "\u001b[1;31mPer ulteriori dettagli, visualizzare Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "test_loaders = []\n",
    "\n",
    "for i in range(8):\n",
    "    if i <= 3:\n",
    "        continue\n",
    "    print(f\"Training on subject {i}\")\n",
    "    sbj_fixs = fixs[i]\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(sbj_fixs, batch_size)\n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    latent_sde = LatentSDE(\n",
    "        data_size=data_size,\n",
    "        latent_size=latent_size,\n",
    "        context_size=context_size,\n",
    "        hidden_size=hidden_size,\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(params=latent_sde.parameters(), lr=lr_init)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=lr_gamma)\n",
    "    #kl_scheduler = LinearScheduler(iters=kl_anneal_iters)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_loss_epoch = 0\n",
    "    latent_sde.train()  # Set the model to training mode\n",
    "\n",
    "    for global_step in tqdm.tqdm(range(1, num_iters + 1)):\n",
    "        # Training step\n",
    "        epoch_train_loss = 0.0\n",
    "        for batch, mask in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            mask = mask.to(device)\n",
    "            ts = torch.linspace(0, 1, batch.size(0), device=device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            log_pxs, log_ratio = latent_sde(batch, mask, ts, noise_std, adjoint, method)\n",
    "            # train_loss = -log_pxs + log_ratio * kl_scheduler.val\n",
    "            train_loss = -log_pxs + log_ratio\n",
    "            epoch_train_loss += train_loss\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            #kl_scheduler.step()\n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        # Validation step\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss = 0.0\n",
    "            latent_sde.eval() # Set the model to evaluation mode\n",
    "            for batch, mask in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                mask = mask.to(device)\n",
    "                ts = torch.linspace(0, 1, batch.size(0), device=device)\n",
    "\n",
    "                log_pxs, log_ratio = latent_sde(batch, mask, ts, noise_std, adjoint, method)\n",
    "                # val_loss = -log_pxs + log_ratio * kl_scheduler.val\n",
    "                val_loss = -log_pxs + log_ratio\n",
    "                epoch_val_loss += val_loss\n",
    "            epoch_val_loss /= len(val_loader)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            latent_sde.train() # Set the model back to training mode\n",
    "\n",
    "        # Logging\n",
    "        if global_step % log_every == 0:\n",
    "            tqdm.tqdm.write(\n",
    "                f\"Sbj {i} | \"\n",
    "                f\"[{global_step:03d}] loss: {epoch_train_loss} | \"\n",
    "                f\"val_loss: {epoch_val_loss} | \"\n",
    "            )\n",
    "        \n",
    "        if (epoch_val_loss < best_val_loss):\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_val_loss_epoch = global_step\n",
    "            torch.save({\n",
    "                'model_state_dict': latent_sde.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': best_val_loss_epoch,\n",
    "                'val_loss': best_val_loss,\n",
    "            }, 'best_latent_sde_' + str(i) + '.pth')\n",
    "\n",
    "    # Plotting training and validation losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses Sbj ' + str(i))\n",
    "    plt.yscale('log') # Log scale for better visibility\n",
    "    plt.axhline(y=best_val_loss, color='red', linestyle='--', label='Best Validation Loss')\n",
    "    plt.axvline(x=best_val_loss_epoch, color='green', linestyle='--', label='Best Validation Iteration')\n",
    "    plt.xticks(range(0, num_iters + 1, log_every))\n",
    "    plt.xlim(0, num_iters)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('losses_sbj_' + str(i) + '.png')\n",
    "\n",
    "# Save test loaders for later use\n",
    "with open(\"test_loaders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_loaders, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "for i in range(8):\n",
    "    Image('losses_sbj_' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0515f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26256456.)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(16, 6))  # 2 righe, 4 colonne\n",
    "axes = axes.flatten()  # Rende l'array bidimensionale in un array 1D per iterare facilmente\n",
    "\n",
    "for i in range(8):\n",
    "    print(f\"Testing on subject {i}\")\n",
    "    checkpoint = torch.load('best_latent_sde_' + str(i) + '.pth')\n",
    "    print(f\"\\tEpoch {checkpoint['epoch']} | Validation loss {checkpoint['val_loss']}\")\n",
    "    epoch = checkpoint['epoch']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "    latent_sde = LatentSDE(\n",
    "        data_size=data_size,\n",
    "        latent_size=latent_size,\n",
    "        context_size=context_size,\n",
    "        hidden_size=hidden_size,\n",
    "    ).to(device)\n",
    "    latent_sde.load_state_dict(checkpoint['model_state_dict'])\n",
    "    latent_sde.eval()  # Set the model to evaluation mode\n",
    "    test_loader = test_loaders[i]\n",
    "\n",
    "    # Test step\n",
    "    with torch.no_grad():\n",
    "        for batch, mask in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            mask = mask.to(device)\n",
    "            ts = torch.linspace(0, 1, batch.size(0), device=device)\n",
    "\n",
    "            _xs = latent_sde.sample(batch.size(0), ts)\n",
    "\n",
    "            x, y = _xs[:, 0], _xs[:, 1]\n",
    "            ax = axes[i]\n",
    "            ax.plot(x, y)\n",
    "            ax.set_title(\"Subject \" + str(i))\n",
    "            ax.set_xlabel(\"X\")\n",
    "            ax.set_ylabel(\"Y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
